{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alex Kappes <br>\n",
    "Problem Set 4 <br>\n",
    "EconS 512\n",
    "\n",
    "**Problem 1**\n",
    "\n",
    "Given the equation $Y_i = \\beta_0 + \\beta_1T_i + u_i$, it is assumed that $T_i \\sim \\text{U}(0,1)$ and $u_i \\sim \\text{N}(0, \\sigma_u^2)$. It is further assumed that $T_i\\ \\forall\\ i \\in I$ is unobservable. The true value for $T_i$ follows $\\tau_{1i} = T_i + \\xi_i$, where $\\xi_i \\sim \\text{N}(0, \\sigma_\\xi^2)$. The true population parameter values are $\\boldsymbol{\\beta} = [0.2, 1.5]$.\n",
    "\n",
    "**(a)** The accuracy of OLS estimation procedures using observed $\\mathbf{T}$ values is presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimation is not accurate within .01. The difference is 0.013\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "T = stats.uniform.rvs(size=1000)\n",
    "u = stats.norm.rvs(scale=0.5, size=1000)\n",
    "xi = stats.norm.rvs(scale=0.4, size=1000)\n",
    "eta = stats.norm.rvs(scale=0.6, size=1000)\n",
    "tau1 = T + xi\n",
    "tau2 = T + eta\n",
    "\n",
    "B = np.array([0.2, 1.5])\n",
    "y = B[0] + B[1]*T + u\n",
    "\n",
    "mod_unobs_slp = sm.OLS(y, sm.add_constant(T)).fit().params[1]\n",
    "\n",
    "if abs(mod_unobs_slp - B[1]) < .01:\n",
    "    print('Estimation is accurate within .01')\n",
    "else:\n",
    "    print('Estimation is not accurate within .01. The difference is', round(mod_unobs_slp - B[1], 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** The true values $\\tau_{1i}$ will provide for a slope estimate approximately equal to $\\beta_1\\frac{\\sigma_T^2}{\\sigma_T^2 + \\sigma_\\xi^2}$. The results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B_1 true value is 0.5 , and is estimated at 0.519\n"
     ]
    }
   ],
   "source": [
    "true_slp = round(B[1]*T.var() / (T.var() + xi.var()), 3)\n",
    "mod_obs_slp = round(sm.OLS(y, sm.add_constant(tau1)).fit().params[1], 3)\n",
    "\n",
    "print('B_1 true value is', true_slp, ', and is estimated at', mod_obs_slp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** Instrumenting $\\tau_{1i}$ with the variable $\\tau_{2i} = T_i + \\eta_i$ for $\\eta_i \\sim \\text{N}(0, \\sigma_\\eta^2)$, where $\\tau_{2i}$ is assumed to be observable, provides the following slope parameter estimate. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The IV estimate is 1.578 , compared to the true population parameter of 1.5\n"
     ]
    }
   ],
   "source": [
    "X = np.array([np.repeat(1, len(y)), tau1]).T\n",
    "Z = np.array([np.repeat(1, len(y)), tau2])\n",
    "B1_iv = np.round(np.linalg.multi_dot([np.linalg.inv(np.dot(Z, X)), Z, y[np.newaxis].T])[1], 3)\n",
    "\n",
    "print('The IV estimate is', float(B1_iv), ', compared to the true population parameter of', B[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**\n",
    "\n",
    "Note: The linear equation is specified in the problem set.\n",
    "\n",
    "**(a)** OLS optimization provides $\\hat{\\beta}_1$ below. A White's Heteroskedastic Consistent covariance matrix estimator is produced below. The standard error used for the $\\hat{\\beta}_1$ confidence interval is taken from the White's covariance estimator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% CI for B_1 is [-0.08105284 -0.02244233]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/home/akappes/WSU/512_MetricsII/ps4_data.csv')\n",
    "\n",
    "X = df[['pct_insclnxtyr', 'mhighgrad', 'msomcol', 'fhighgrad', 'fsomcol', 'parincome', 'afqt']].dropna()\n",
    "y = df.loc[list(X.index), 'dayssmklm17']\n",
    "mod = sm.OLS(y, sm.add_constant(X)).fit()\n",
    "\n",
    "# White's HC estimator\n",
    "e_sq = np.array(np.power(mod.resid, 2))\n",
    "Xmat = np.concatenate((np.repeat(1, len(X.index))[np.newaxis].T, X), axis=1)\n",
    "k = Xmat.shape[1]\n",
    "n = Xmat.shape[0]\n",
    "\n",
    "w = np.zeros((k, k))\n",
    "i = 1\n",
    "\n",
    "while i < n:\n",
    "\n",
    "    w = w + e_sq[i] * Xmat[i][np.newaxis].T * Xmat[i]\n",
    "    i = i + 1\n",
    "\n",
    "    if i > n:\n",
    "        break\n",
    "\n",
    "w_hce = np.linalg.multi_dot([np.linalg.inv(np.dot(Xmat.T, Xmat)),\n",
    "                             w,\n",
    "                             np.linalg.inv(np.dot(Xmat.T, Xmat))])\n",
    "\n",
    "w_se = np.sqrt(np.diag(w_hce))\n",
    "\n",
    "# Robust B1 CI\n",
    "alpha = .05\n",
    "t_crit = stats.t.ppf(1-alpha/2, n-k)\n",
    "\n",
    "b1_ci = np.array([mod.params[1] - t_crit * w_se[1],\n",
    "                  mod.params[1] + t_crit * w_se[1]])\n",
    "\n",
    "print('The 95% CI for B_1 is', b1_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)** Random $\\mathbf{X}$ bootstrap sampling for $\\hat{\\beta}_1$ is produced below. The sampling provides a distribution of 1000 $\\hat{\\beta}_1$ and $se\\{\\hat{\\beta}_1\\}$ estimates. The means of bootstrapped $\\hat{\\beta}_1$ and $se\\{\\hat{\\beta}_1\\}$ are used to create the bootstrap $\\hat{\\beta}_1$ confidence interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% CI for bootstrapped B_1 is [-0.07704628 -0.02665728]\n"
     ]
    }
   ],
   "source": [
    "n_boot = 1000\n",
    "boot_mat = pd.concat([pd.DataFrame(y), X], axis=1).reset_index()\n",
    "boot_vals = pd.DataFrame({'b1_boot': 0, 'se_boot': 0}, index=range(n_boot))\n",
    "\n",
    "for i in range(len(boot_vals)):\n",
    "\n",
    "    boot_sample = boot_mat.sample(n, replace=True)\n",
    "    X_boot = boot_sample[['pct_insclnxtyr', 'mhighgrad', 'msomcol', 'fhighgrad', 'fsomcol', 'parincome', 'afqt']]\n",
    "    y_boot = boot_sample['dayssmklm17']\n",
    "\n",
    "    boot_vals.loc[i, 'b1_boot'] = sm.OLS(y_boot, sm.add_constant(X_boot)).fit().params[1]\n",
    "    boot_vals.loc[i, 'se_boot'] = sm.OLS(y_boot, sm.add_constant(X_boot)).fit().bse[1]\n",
    "\n",
    "b1_boot_mean = boot_vals['b1_boot'].mean()\n",
    "se_boot_mean = boot_vals['se_boot'].mean()\n",
    "\n",
    "b1_boot_ci = np.array([b1_boot_mean - t_crit * se_boot_mean,\n",
    "                       b1_boot_mean + t_crit * se_boot_mean])\n",
    "\n",
    "print('The 95% CI for bootstrapped B_1 is', b1_boot_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bootstrapped $\\hat{\\beta}_1$ confidence interval has shrunk around the *true* $\\beta_1$ population paramter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)** The bootstrap process for $\\hat{\\beta}_1$ is repeated using a just-identified instrumental variable approach. The bootstrap $\\hat{\\beta}_1$ confidence interval is produced below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The 95% CI for IV bootstrapped B_1 is [-0.53605269  0.29218561]\n"
     ]
    }
   ],
   "source": [
    "boot_iv_mat = pd.concat([pd.DataFrame(y), df.loc[list(X.index), 'ctuition17'], X], axis=1).reset_index()\n",
    "boot_iv_vals = pd.DataFrame({'b1_iv_boot': 0, 'se_iv_boot': 0}, index=range(n_boot))\n",
    "\n",
    "for i in range(len(boot_iv_vals)):\n",
    "\n",
    "    boot_iv_sample = boot_iv_mat.sample(n, replace=True)\n",
    "    Z_boot = np.concatenate((np.repeat(1, len(boot_iv_sample.index))[np.newaxis].T,\n",
    "                             boot_iv_sample[['ctuition17', 'mhighgrad', 'msomcol', 'fhighgrad',\n",
    "                                             'fsomcol', 'parincome', 'afqt']]),\n",
    "                            axis=1)\n",
    "    X_boot = np.concatenate((np.repeat(1, len(boot_iv_sample.index))[np.newaxis].T,\n",
    "                             boot_iv_sample[['pct_insclnxtyr', 'mhighgrad', 'msomcol', 'fhighgrad',\n",
    "                                             'fsomcol', 'parincome', 'afqt']]),\n",
    "                            axis=1)\n",
    "    y_boot = np.array(boot_iv_sample['dayssmklm17'])[np.newaxis].T\n",
    "\n",
    "    B_iv_boot = np.linalg.multi_dot([np.linalg.inv(np.dot(Z_boot.T, X_boot)), Z_boot.T, y_boot])\n",
    "\n",
    "    sig2 = np.dot(np.array((y_boot - np.dot(X_boot, B_iv_boot))).T, (y_boot - np.dot(X_boot, B_iv_boot))) / (n - k)\n",
    "\n",
    "    cov_B_iv = sig2 * np.linalg.multi_dot([np.linalg.inv(np.dot(Z_boot.T, X_boot)),\n",
    "                                           np.dot(Z_boot.T, Z_boot),\n",
    "                                           np.linalg.inv(np.dot(X_boot.T, Z_boot))])\n",
    "\n",
    "    boot_iv_vals.loc[i, 'b1_iv_boot'] = B_iv_boot[1]\n",
    "    boot_iv_vals.loc[i, 'se_iv_boot'] = np.sqrt(np.diag(cov_B_iv))[1]\n",
    "\n",
    "b1_iv_boot_mean = boot_iv_vals['b1_iv_boot'].mean()\n",
    "se_iv_boot_mean = boot_iv_vals['se_iv_boot'].mean()\n",
    "\n",
    "b1_iv_boot_ci = np.array([b1_iv_boot_mean - t_crit * se_iv_boot_mean,\n",
    "                          b1_iv_boot_mean + t_crit * se_iv_boot_mean])\n",
    "\n",
    "print('The 95% CI for IV bootstrapped B_1 is', b1_iv_boot_ci)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IV bootstrapped CI shows that under IV framework, the instrument is not significant in explaining variation in the dependent variable. The working paper by Alwyn Young titled *Consistency without Inference: Instrumental Variables in Practical Application* eludes to this result in the explanation of there being less variability in IV estimation procedures. When bootstrapping, the results are often more sensitive to influential observations, leading to wider variability in parameter estimates and significance.  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
