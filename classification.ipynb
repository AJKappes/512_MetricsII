{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiana Randriamaro <br>\n",
    "Alex Kappes\n",
    "Econs 514"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST database contains 60,000 training images and 10,000 testing images taken from American Census Bureau employees and American high school students. It is separated into two groups as train and test and also separated into the labels and the images. x_train and x_test parts contain greyscale RGB codes (from 0 to 255) while y_train and y_test parts contains labels from 0 to 9 which represents which number they actually are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data with matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0xb276cdcc0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#%matplotlib inline # Only use this if using iPython\n",
    "image_index = 14000 # Ranges from 0 to 60,000\n",
    "print(y_train[image_index]) # The label is 1\n",
    "plt.imshow(x_train[image_index], cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reshaping and normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "Number of images in x_train 60000\n",
      "Number of images in x_test 10000\n"
     ]
    }
   ],
   "source": [
    "# Reshaping the array to 4-dims so that it can work with the Keras API\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "input_shape = (28, 28, 1)\n",
    "# The values are float so that we can get decimal points after division\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print('x_train shape:', x_train.shape)\n",
    "print('Number of images in x_train', x_train.shape[0])\n",
    "print('Number of images in x_test', x_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing the required Keras modules containing model and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D\n",
    "# Creating a Sequential Model and adding the layers\n",
    "model = Sequential()\n",
    "model.add(Conv2D(28, kernel_size=(3,3), input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Flatten()) # Flattening the 2D arrays for fully connected layers\n",
    "model.add(Dense(128, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(10,activation=tf.nn.softmax)) # 10 neurons for 10 number classes (0,1,..9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 147s 2ms/step - loss: 0.2036 - acc: 0.9386\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 131s 2ms/step - loss: 0.0826 - acc: 0.9746\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 113s 2ms/step - loss: 0.0564 - acc: 0.9825\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 141s 2ms/step - loss: 0.0438 - acc: 0.9855\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 127s 2ms/step - loss: 0.0350 - acc: 0.9886\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 136s 2ms/step - loss: 0.0292 - acc: 0.9905\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0239 - acc: 0.9919\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.0222 - acc: 0.9922\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 142s 2ms/step - loss: 0.0206 - acc: 0.9930\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 117s 2ms/step - loss: 0.0182 - acc: 0.9941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0xb266c7978>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compiling and fitting the model\n",
    "model.compile(optimizer='adam', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.fit(x=x_train,y=y_train, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 6s 553us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.06720509715685112, 0.9824]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model achieves 98.24% accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_index = 4444\n",
    "plt.imshow(x_test[image_index].reshape(28, 28),cmap='Greys')\n",
    "pred = model.predict(x_test[image_index].reshape(1, 28, 28, 1))\n",
    "print(pred.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model succesfully qualifies the image above as 9."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Classfication Tree\n",
    "\n",
    "The code below develops a classification regression tree using root mean squared error as the cost function. Prediction values are printed as final output. Data used for classification is generated and has no real meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction values for test data are: \n",
      " \n",
      " [4.17440313 4.17440313 4.17440313 4.17440313 4.17440313 4.17440313\n",
      " 4.17440313 4.17440313 4.17440313 4.17440313 4.17440313 4.17440313\n",
      " 4.17440313 4.17440313 4.17440313 4.17440313 4.17440313 4.17440313\n",
      " 4.17440313 4.17440313]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "###\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "###\n",
    "\n",
    "#### Classification Tree ####\n",
    "\n",
    "# generate random data instead of loading from /home/ajkappes directory #\n",
    "def vars(j, var):\n",
    "    vars = []\n",
    "    l = 1\n",
    "    for i in range(j):\n",
    "        vars.append(var + str(l))\n",
    "        l += 1\n",
    "    return vars\n",
    "\n",
    "def generate_data(n, indicate, test_split):\n",
    "    alpha = 0.75\n",
    "    X = vars(2, 'x')\n",
    "    df = pd.DataFrame({X[0]: stats.norm.rvs(loc=5, scale=0.75, size=n),\n",
    "                       X[1]: stats.norm.rvs(loc=2, scale=0.25, size=n)})\n",
    "    df['y'] = alpha * df[X[0]] + (1 - alpha) * df[X[1]]\n",
    "    df['y_bin'] = np.where(df['y'] > df['y'].mean(), 1, 0)\n",
    "\n",
    "    train_idx = list(np.random.choice(df.index.tolist(), size=int((1 - test_split) * len(df)), replace=False))\n",
    "    if indicate == 'train':\n",
    "        return df.loc[train_idx]\n",
    "\n",
    "    else:\n",
    "        return df.loc[[idx for idx in df.index if idx not in train_idx]]\n",
    "\n",
    "df_train = generate_data(100,'train', 0.2)\n",
    "X_train = df_train[['x1', 'x2']]\n",
    "y_train = df_train['y']\n",
    "\n",
    "df_test = generate_data(100, 'test', 0.2)\n",
    "X_test = df_test[['x1', 'x2']]\n",
    "y_test = df_test['y']\n",
    "\n",
    "class node:\n",
    "    def __init__(self, x, y, idx, min_leaf_sample):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.idx = idx\n",
    "        self.min_leaf_sample = min_leaf_sample\n",
    "        self.cost_init = np.inf\n",
    "\n",
    "    def generate_split(self, x_j):\n",
    "        x = self.x.values[idx, x_j]\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            split_left = x[x <= x[i]]\n",
    "            split_right = x[x > x[i]]\n",
    "\n",
    "            if len(split_left) < self.min_leaf_sample or len(split_right) < self.min_leaf_sample:\n",
    "                continue\n",
    "\n",
    "            cost = self.get_cost(left, right)\n",
    "            if cost < self.cost_init:\n",
    "                self.cost_init = cost\n",
    "                self.x_j = x_j\n",
    "                self.split = x[i]\n",
    "\n",
    "    def get_cost(self, left, right):\n",
    "        left_std = self.y[self.idx][left]\n",
    "        right_std = self.y[self.idx][right]\n",
    "        return left_std * len(split_left) + right_std * len(split_right)\n",
    "\n",
    "    def generate_var_split(self):\n",
    "        for j in range(self.x.shape[1]):\n",
    "            if self.leaf == True:\n",
    "                return\n",
    "            x = self.split_var\n",
    "            left = np.nonzero(x <= self.split)[0]\n",
    "            right = np.nonzero(x > self.split)[0]\n",
    "            self.left = node(self.x, self.y, self.idx[left], self.min_leaf_sample)\n",
    "            self.right = node(self.x, self.y, self.idx[right], self.min_leaf_sample)\n",
    "\n",
    "    @property\n",
    "    def split_var(self):\n",
    "        return self.x.values[self.idx, self.x_j]\n",
    "\n",
    "    @property\n",
    "    def leaf(self):\n",
    "        return self.cost_init == float(np.inf)\n",
    "\n",
    "    def predict_idx(self, x_i):\n",
    "        if self.leaf == True:\n",
    "            return np.mean(self.y[self.idx])\n",
    "\n",
    "        if x_i[self.x_j] <= self.split:\n",
    "            d_node = self.left\n",
    "        else:\n",
    "            d_node = self.right\n",
    "\n",
    "        return d_node.predict_idx(x_i)\n",
    "\n",
    "    def prediction(self, x):\n",
    "        return np.array([self.predict_idx(x_i) for x_i in x])\n",
    "\n",
    "class decision_tree:\n",
    "\n",
    "    def fit(self, x, y, min_leaf_sample):\n",
    "        self.decisiontree = node(x, y, np.arange(len(y)), min_leaf_sample)\n",
    "        return self\n",
    "\n",
    "    def prediction(self, x):\n",
    "        return self.decisiontree.prediction(x.values)\n",
    "\n",
    "\n",
    "d_test_tree = decision_tree().fit(X_test, y_test, min_leaf_sample=10)\n",
    "d_test_tree_predict = d_test_tree.prediction(X_test)\n",
    "\n",
    "print('Prediction values for test data are:', '\\n \\n', d_test_tree_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction values correspond to mean leaf values at terminal nodes. They appear to be uniform across the test data set due to data generation following a small interval. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.07300949265772\n"
     ]
    }
   ],
   "source": [
    "print(df_test['y'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y</th>\n",
       "      <th>y_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.500512</td>\n",
       "      <td>1.726770</td>\n",
       "      <td>3.807077</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4.448824</td>\n",
       "      <td>1.866298</td>\n",
       "      <td>3.803192</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.208152</td>\n",
       "      <td>2.346360</td>\n",
       "      <td>4.492704</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.170585</td>\n",
       "      <td>2.228855</td>\n",
       "      <td>5.185152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4.105588</td>\n",
       "      <td>2.018800</td>\n",
       "      <td>3.583891</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5.092602</td>\n",
       "      <td>1.968971</td>\n",
       "      <td>4.311695</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.053766</td>\n",
       "      <td>2.430680</td>\n",
       "      <td>4.397995</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>6.329394</td>\n",
       "      <td>1.886616</td>\n",
       "      <td>5.218700</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>3.796074</td>\n",
       "      <td>1.601571</td>\n",
       "      <td>3.247448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>3.290993</td>\n",
       "      <td>2.275941</td>\n",
       "      <td>3.037230</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>4.177595</td>\n",
       "      <td>1.547212</td>\n",
       "      <td>3.519999</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.126852</td>\n",
       "      <td>1.834563</td>\n",
       "      <td>3.553780</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>4.543484</td>\n",
       "      <td>1.987311</td>\n",
       "      <td>3.904441</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>3.559892</td>\n",
       "      <td>1.721224</td>\n",
       "      <td>3.100225</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>4.445004</td>\n",
       "      <td>2.418583</td>\n",
       "      <td>3.938399</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>6.355255</td>\n",
       "      <td>2.295372</td>\n",
       "      <td>5.340284</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>4.731910</td>\n",
       "      <td>2.366462</td>\n",
       "      <td>4.140548</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>4.437187</td>\n",
       "      <td>1.813986</td>\n",
       "      <td>3.781387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>5.211608</td>\n",
       "      <td>1.998965</td>\n",
       "      <td>4.408447</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5.604124</td>\n",
       "      <td>1.938014</td>\n",
       "      <td>4.687596</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          x1        x2         y  y_bin\n",
       "0   4.500512  1.726770  3.807077      0\n",
       "10  4.448824  1.866298  3.803192      0\n",
       "11  5.208152  2.346360  4.492704      1\n",
       "16  6.170585  2.228855  5.185152      1\n",
       "19  4.105588  2.018800  3.583891      0\n",
       "20  5.092602  1.968971  4.311695      1\n",
       "26  5.053766  2.430680  4.397995      1\n",
       "33  6.329394  1.886616  5.218700      1\n",
       "34  3.796074  1.601571  3.247448      0\n",
       "35  3.290993  2.275941  3.037230      0\n",
       "40  4.177595  1.547212  3.519999      0\n",
       "42  4.126852  1.834563  3.553780      0\n",
       "53  4.543484  1.987311  3.904441      0\n",
       "56  3.559892  1.721224  3.100225      0\n",
       "58  4.445004  2.418583  3.938399      0\n",
       "63  6.355255  2.295372  5.340284      1\n",
       "67  4.731910  2.366462  4.140548      0\n",
       "86  4.437187  1.813986  3.781387      0\n",
       "89  5.211608  1.998965  4.408447      1\n",
       "97  5.604124  1.938014  4.687596      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
