{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alex Kappes <br>\n",
    "Problem Set 6 <br>\n",
    "EconS 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "import pandas as pd\n",
    "\n",
    "class estimate:\n",
    "    def __init__(self, dep, indep, df):\n",
    "        self.dep = np.asmatrix(dep).T\n",
    "        self.indep = np.asmatrix(indep)\n",
    "        self.df = df\n",
    "\n",
    "\n",
    "    # parameters\n",
    "    def beta(self):\n",
    "        b = inv(self.indep.T * self.indep) * self.indep.T * self.dep\n",
    "        return b\n",
    "\n",
    "\n",
    "    # residuals\n",
    "    def error(self, beta):\n",
    "        resid = self.dep - self.indep * beta\n",
    "        return resid\n",
    "\n",
    "\n",
    "    # Whites HC covariance estimator\n",
    "    def robust(self, e):\n",
    "        k = self.indep.shape[1]\n",
    "        n = self.indep.shape[0]\n",
    "\n",
    "        s = np.zeros((k, k))\n",
    "        i = 1\n",
    "\n",
    "        while i < n:\n",
    "\n",
    "            s = s + e[i, 0]**2 * self.indep[i].T * self.indep[i]\n",
    "            i = i + 1\n",
    "\n",
    "            if i > n:\n",
    "                break\n",
    "\n",
    "        w_hce = inv(self.indep.T * self.indep) * s * inv(self.indep.T * self.indep)\n",
    "        w_se = np.sqrt(np.diag(w_hce))\n",
    "        return w_se\n",
    "\n",
    "\n",
    "    # construction of se clustered by state\n",
    "    def se_cluster_s(self, g, e):\n",
    "        group_s = pd.DataFrame(df[g].unique().tolist()).rename(columns={0: 'group'})\n",
    "\n",
    "        l_s = {}\n",
    "        for i in group_s['group']:\n",
    "            l_s[i] = pd.DataFrame()\n",
    "\n",
    "        for key in l_s:\n",
    "            l_s[key] = df[df[g] == key].index.tolist()\n",
    "\n",
    "        group_e = pd.DataFrame(e).rename(columns={0: 'ehat'})\n",
    "\n",
    "        d_sigsq = {}\n",
    "        for i in group_s['group']:\n",
    "            d_sigsq[i] = pd.DataFrame()\n",
    "\n",
    "        for key in d_sigsq:\n",
    "            d_sigsq[key] = (np.asmatrix(group_e.loc[l_s[key]]).T *\n",
    "                            np.asmatrix(group_e.loc[l_s[key]])) / len(l_s[key])\n",
    "\n",
    "        sigsq_df = pd.DataFrame({'sigsq': 0}, index=df.index)\n",
    "\n",
    "        for key in d_sigsq:\n",
    "            sigsq_df.loc[df[df[g] == key].index.tolist(), 'sigsq'] = d_sigsq[key][0, 0]\n",
    "\n",
    "        sigsq_l = np.array(sigsq_df)\n",
    "        s = np.multiply(np.divide(1, sigsq_l), np.eye(len(self.indep)))\n",
    "        covmat_s = inv(self.indep.T * s * self.indep)\n",
    "        return np.sqrt(np.diag(covmat_s))\n",
    "\n",
    "        # Code commented out below follows Greene's equations for clustered covmat estimator:\n",
    "        # he specifies by grouping and summing over all groups but this produces singular x_g'x_g\n",
    "        # matrices for all of this binary fixed effect data. I've created an identy matrix with\n",
    "        # repeated 1 / sighat_g^2 values corresponding to index values in X.\n",
    "        # Each within group obs is weighted appropriately and det(X) exists, providing\n",
    "        # a computable clustered covmat estimator. Code below is kept for future reference.\n",
    "        \n",
    "        # xtxi = {}\n",
    "        # for state in group_s['group']:\n",
    "        #     xtxi[state] = pd.DataFrame()\n",
    "        #\n",
    "        # for key in xtxi:\n",
    "        #     xtxi[key] = inv(np.asmatrix(df[df[g] == key][x_vars]).T * np.asmatrix(df[df[g] == key][x_vars]))\n",
    "        #\n",
    "        # covmat_s_g = {}\n",
    "        # for state in group_s['group']:\n",
    "        #     covmat_s_g[state] = pd.DataFrame()\n",
    "        #\n",
    "        # for key in covmat_s_g:\n",
    "        #     covmat_s_g[key] = d_sigsq[key] * xtxi[key]\n",
    "        #\n",
    "        # covmat_l = [covmat_s_g[group_s.loc[0, 'group']]]\n",
    "        # i = 1\n",
    "        # while i < len(group_s):\n",
    "        #     covmat_l.append(covmat_s_g[group_s.loc[i, 'group']])\n",
    "        #     i += 1\n",
    "        #     if i > len(group_s):\n",
    "        #         break\n",
    "        #\n",
    "        # covmat_s = sum(covmat_l)\n",
    "        # return np.sqrt(np.diag(covmat_s))\n",
    "\n",
    "\n",
    "    # construction of se clustered by state and year\n",
    "    def se_cluster_multi(self, g1, g2, e):\n",
    "        group_1 = df[g1].unique().tolist()\n",
    "        group_2 = df[g2].unique().tolist()\n",
    "\n",
    "        group_e = pd.DataFrame(e).rename(columns={0: 'ehat'})\n",
    "\n",
    "        l_multi_idx = []\n",
    "        for i in group_1:\n",
    "            for j in group_2:\n",
    "                l_multi_idx.append(df[(df[g1] == i) & (df[g2] == j)].index)\n",
    "\n",
    "        i = 0\n",
    "        sighat_multi_l = []\n",
    "        while i < len(l_multi_idx):\n",
    "            sighat_multi_l.append(np.asmatrix(group_e.loc[l_multi_idx[i].tolist()]).T *\n",
    "                                  np.asmatrix(group_e.loc[l_multi_idx[i].tolist()]) / len(l_multi_idx[i]))\n",
    "            i += 1\n",
    "            if i > len(l_multi_idx):\n",
    "                break\n",
    "\n",
    "        sigsq_multi_df = pd.DataFrame({'sigsq_multi': 0}, index=df.index)\n",
    "\n",
    "        for i in range(len(l_multi_idx)):\n",
    "            sigsq_multi_df.loc[l_multi_idx[i].tolist()] = sighat_multi_l[i][0, 0]\n",
    "\n",
    "        sigsq_multi_l = np.array(sigsq_multi_df)\n",
    "        g_multi = np.multiply(np.divide(1, sigsq_multi_l), np.eye(len(self.indep)))\n",
    "        covmat_g_multi = inv(self.indep.T * g_multi * self.indep)\n",
    "        return np.sqrt(np.diag(covmat_g_multi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "### data construction ###\n",
    "df = pd.read_csv('/home/akappes/WSU/512_MetricsII/merit_data.csv')\n",
    "\n",
    "bin_state = pd.DataFrame(0, columns=df['state'].unique().tolist()[:-1], index=df.index)\n",
    "bin_year = pd.DataFrame(0, columns=df['year'].unique().tolist()[:-1], index=df.index)\n",
    "\n",
    "for j in bin_state.columns:\n",
    "    bin_state.loc[df[df['state'] == j].index.tolist(), j] = 1\n",
    "\n",
    "for j in bin_year.columns:\n",
    "    bin_year.loc[df[df['year'] == j].index.tolist(), j] = 1\n",
    "\n",
    "df.insert(loc=0, column='ones', value=1)\n",
    "df = pd.concat([df, bin_state, bin_year], axis=1)\n",
    "\n",
    "X = df.drop(['coll', 'year', 'state', 'chst'], axis=1)\n",
    "x_vars = X.columns[1:5].tolist()\n",
    "x_fe = X.columns[5:].tolist()\n",
    "y = df['coll']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X variables: \n",
      " ['merit', 'male', 'black', 'asian'] \n",
      " \n",
      " X fixed effects: \n",
      " [11, 12, 13, 14, 15, 16, 21, 22, 23, 31, 32, 33, 34, 35, 41, 42, 43, 44, 45, 46, 47, 51, 52, 53, 54, 55, 56, 57, 58, 59, 61, 62, 63, 64, 71, 72, 73, 74, 81, 82, 83, 84, 85, 86, 87, 88, 91, 92, 93, 94, 1993, 1997, 1992, 1989, 1991, 1999, 1994, 1998, 2000, 1995, 1990]\n"
     ]
    }
   ],
   "source": [
    "est_a = estimate(y, X, df)\n",
    "params_a = est_a.beta()\n",
    "resids_a = est_a.error(params_a)\n",
    "whites_hce_a = est_a.robust(resids_a)\n",
    "clustered_state_se_a = est_a.se_cluster_s('state', resids_a)\n",
    "clustered_stateyear_se_a = est_a.se_cluster_multi('state', 'year', resids_a)\n",
    "\n",
    "print('X variables: \\n', x_vars, '\\n \\n X fixed effects: \\n', x_fe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters: \n",
      " [[ 0.427  0.034 -0.079 -0.15   0.169]]\n"
     ]
    }
   ],
   "source": [
    "print('Estimated parameters: \\n', np.round(np.array(params_a[0:5].T), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White's HC covariance estimator standard errors: \n",
      " [0.02917 0.01451 0.00476 0.00732 0.01344 0.03699 0.03843 0.03899 0.03123\n",
      " 0.03867 0.03706 0.02926 0.03039 0.0302  0.03015 0.03468 0.03015 0.03011\n",
      " 0.03456 0.03496 0.03471 0.03612 0.03396 0.03339 0.03409 0.03451 0.03778\n",
      " 0.03813 0.03822 0.03422 0.0343  0.0307  0.03507 0.03509 0.03057 0.03501\n",
      " 0.03459 0.03414 0.03495 0.03608 0.03441 0.03472 0.02963 0.03436 0.03357\n",
      " 0.03481 0.03579 0.03473 0.03465 0.03334 0.03598 0.03605 0.03515 0.0285\n",
      " 0.03455 0.01195 0.01229 0.01191 0.01142 0.01175 0.01222 0.01202 0.01224\n",
      " 0.0125  0.01216 0.0116 ]\n"
     ]
    }
   ],
   "source": [
    "print(\"White's HC covariance estimator standard errors: \\n\", np.round(whites_hce_a, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered state standard errors: \n",
      " [0.02918 0.01449 0.00476 0.00753 0.01364 0.03699 0.03841 0.03897 0.03118\n",
      " 0.03867 0.03705 0.02926 0.03042 0.0302  0.03014 0.03467 0.03015 0.03012\n",
      " 0.03454 0.03493 0.03474 0.03612 0.03395 0.03337 0.0341  0.03447 0.03779\n",
      " 0.03816 0.03825 0.03425 0.03428 0.03068 0.03505 0.0351  0.03055 0.03499\n",
      " 0.03457 0.03412 0.03493 0.03612 0.0344  0.0347  0.02962 0.03435 0.03357\n",
      " 0.03479 0.03576 0.03472 0.03464 0.03333 0.03596 0.03605 0.03516 0.02852\n",
      " 0.03452 0.01197 0.01231 0.01196 0.01147 0.01178 0.01225 0.01207 0.01226\n",
      " 0.01252 0.01223 0.01162]\n"
     ]
    }
   ],
   "source": [
    "print('Clustered state standard errors: \\n', np.round(clustered_state_se_a, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered state and year standard errors: \n",
      " [0.02912 0.01447 0.00476 0.00752 0.01364 0.0369  0.03835 0.03889 0.03115\n",
      " 0.03863 0.037   0.02922 0.03038 0.03017 0.0301  0.03462 0.03011 0.03009\n",
      " 0.0345  0.03489 0.0347  0.03608 0.03392 0.03332 0.03406 0.03443 0.03769\n",
      " 0.0381  0.03806 0.03421 0.03421 0.03065 0.03501 0.03499 0.03051 0.03493\n",
      " 0.03444 0.03408 0.03487 0.03598 0.03434 0.03465 0.02958 0.03431 0.0335\n",
      " 0.03474 0.03566 0.03462 0.03456 0.03329 0.0358  0.03599 0.03509 0.02848\n",
      " 0.03447 0.01192 0.01226 0.01188 0.0114  0.01173 0.0122  0.012   0.01221\n",
      " 0.01247 0.01213 0.01157]\n"
     ]
    }
   ],
   "source": [
    "print('Clustered state and year standard errors: \\n', np.round(clustered_stateyear_se_a, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(b)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated state-weighted parameters: \n",
      " [[  0.432   2.331  -5.516 -10.196  11.582]]\n"
     ]
    }
   ],
   "source": [
    "years = df['year'].unique().tolist()\n",
    "\n",
    "weights = []\n",
    "for i in years:\n",
    "    weights.append(len(df[df['year'] == i]['state'].unique()) /\n",
    "                   len(df[df['year'] == i]['state']))\n",
    "\n",
    "year_idx = []\n",
    "for i in years:\n",
    "    year_idx.append(df[df['year'] == i].index.tolist())\n",
    "\n",
    "X_weighted = pd.DataFrame(0, columns=x_vars, index=X.index)\n",
    "\n",
    "for i in range(len(weights)) and range(len(year_idx)):\n",
    "    X_weighted.loc[year_idx[i]] = weights[i] * X.loc[year_idx[i], x_vars]\n",
    "\n",
    "X_weighted = pd.concat([X['ones'], X_weighted, X[x_fe]], axis=1)\n",
    "\n",
    "est_b = estimate(y, X_weighted, df)\n",
    "params_b = est_b.beta()\n",
    "\n",
    "print('Estimated state-weighted parameters: \\n', np.round(np.array(params_b[0:5].T), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(c)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated (state x year) mean-weighted parameters: \n",
      " [[ 0.337  0.034 -0.155 -0.541  0.37 ]]\n"
     ]
    }
   ],
   "source": [
    "s_group = df['state'].unique().tolist()\n",
    "y_group = df['year'].unique().tolist()\n",
    "\n",
    "sy_idx = []\n",
    "for i in s_group:\n",
    "    for j in y_group:\n",
    "        sy_idx.append(df[(df['state'] == i) & (df['year'] == j)].index)\n",
    "\n",
    "mean_l = []\n",
    "i = 0\n",
    "while i < len(sy_idx):\n",
    "    mean_l.append(X.loc[sy_idx[i], x_vars].mean().tolist())\n",
    "    i += 1\n",
    "    if i > len(sy_idx):\n",
    "        break\n",
    "\n",
    "X_means = pd.DataFrame(0, columns=x_vars, index=X.index)\n",
    "\n",
    "for i in range(len(sy_idx)) and range(len(mean_l)):\n",
    "    X_means.loc[sy_idx[i]] = mean_l[i] * X.loc[sy_idx[i], x_vars]\n",
    "\n",
    "X_means = pd.concat([X['ones'], X_means, X[x_fe]], axis=1)\n",
    "\n",
    "est_c = estimate(y, X_means, df)\n",
    "params_c = est_c.beta()\n",
    "resids_c = est_c.error(params_c)\n",
    "whites_hce_c = est_c.robust(resids_c)\n",
    "clustered_state_se_c = est_c.se_cluster_s('state', resids_c)\n",
    "\n",
    "print('Estimated (state x year) mean-weighted parameters: \\n', np.round(np.array(params_c[0:5].T), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White's HC covariance estimator standard errors: \n",
      " [0.05071 0.01456 0.00943 0.02919 0.07101 0.05553 0.05643 0.05685 0.05182\n",
      " 0.05673 0.0556  0.05068 0.05131 0.05128 0.05123 0.05404 0.05122 0.05121\n",
      " 0.0539  0.05421 0.05403 0.055   0.05356 0.05318 0.05371 0.05385 0.05598\n",
      " 0.05634 0.05903 0.05357 0.05373 0.05153 0.05436 0.05432 0.05141 0.05421\n",
      " 0.05397 0.05374 0.05458 0.05481 0.05388 0.05405 0.05095 0.05384 0.05335\n",
      " 0.05411 0.05468 0.05397 0.05399 0.05317 0.0547  0.05489 0.05436 0.04953\n",
      " 0.05381 0.01199 0.01231 0.01196 0.01146 0.0118  0.01226 0.01207 0.01227\n",
      " 0.01255 0.01222 0.01164]\n"
     ]
    }
   ],
   "source": [
    "print(\"White's HC covariance estimator standard errors: \\n\", np.round(whites_hce_c, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered state standard errors: \n",
      " [0.04838 0.01453 0.00943 0.02952 0.0688  0.05341 0.05434 0.05477 0.04953\n",
      " 0.05465 0.05348 0.04835 0.04904 0.04897 0.04892 0.05184 0.04892 0.0489\n",
      " 0.05171 0.05203 0.05186 0.05285 0.05135 0.05095 0.05151 0.05166 0.05387\n",
      " 0.05425 0.05709 0.05145 0.05153 0.04923 0.0522  0.05218 0.04912 0.05204\n",
      " 0.05177 0.05154 0.05244 0.05271 0.05169 0.05186 0.04861 0.05164 0.05112\n",
      " 0.05192 0.05251 0.05179 0.05179 0.05094 0.05256 0.05274 0.05218 0.04722\n",
      " 0.05162 0.012   0.01234 0.012   0.01151 0.01182 0.01228 0.01211 0.01229\n",
      " 0.01256 0.01226 0.01165]\n"
     ]
    }
   ],
   "source": [
    "print('Clustered state standard errors: \\n', np.round(clustered_state_se_c, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(d)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated (state x year) sample-weighted parameters: \n",
      " [[  0.497  10.085 -15.355 -35.825  36.314]]\n"
     ]
    }
   ],
   "source": [
    "weights_sample = []\n",
    "i = 0\n",
    "while i < len(sy_idx):\n",
    "    weights_sample.append(len(sy_idx[i]) / len(df))\n",
    "    i += 1\n",
    "    if i > len(sy_idx):\n",
    "        break\n",
    "\n",
    "X_weighted_sample = pd.DataFrame(0, columns=x_vars, index=X.index)\n",
    "\n",
    "for i in range(len(sy_idx)) and range(len(weights_sample)):\n",
    "    X_weighted_sample.loc[sy_idx[i]] = weights_sample[i] * X.loc[sy_idx[i], x_vars]\n",
    "\n",
    "X_weighted_sample = pd.concat([X['ones'], X_weighted_sample, X[x_fe]], axis=1)\n",
    "\n",
    "est_d = estimate(y, X_weighted_sample, df)\n",
    "params_d = est_d.beta()\n",
    "resids_d = est_d.error(params_d)\n",
    "whites_hce_d = est_d.robust(resids_d)\n",
    "clustered_state_se_d = est_d.se_cluster_s('state', resids_d)\n",
    "\n",
    "print('Estimated (state x year) sample-weighted parameters: \\n', np.round(np.array(params_d[0:5].T), 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "White's HC covariance estimator standard errors: \n",
      " [0.02715 6.37494 1.39868 2.17349 2.92756 0.03552 0.03716 0.03765 0.02953\n",
      " 0.0375  0.03579 0.02787 0.02888 0.02855 0.02843 0.03327 0.02854 0.0285\n",
      " 0.03291 0.03352 0.03346 0.03472 0.03244 0.03173 0.03261 0.03296 0.03679\n",
      " 0.0371  0.03723 0.03292 0.03264 0.02902 0.03362 0.0326  0.02934 0.03347\n",
      " 0.03313 0.03252 0.03306 0.03308 0.0327  0.03319 0.02798 0.03276 0.03203\n",
      " 0.03327 0.03424 0.0329  0.0331  0.03185 0.03443 0.03471 0.03387 0.02755\n",
      " 0.03301 0.01201 0.01234 0.01195 0.01148 0.01181 0.01226 0.01207 0.01228\n",
      " 0.01255 0.01221 0.01165]\n"
     ]
    }
   ],
   "source": [
    "print(\"White's HC covariance estimator standard errors: \\n\", np.round(whites_hce_d, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clustered state standard errors: \n",
      " [0.02717 6.35705 1.40068 2.19487 2.97305 0.03554 0.03717 0.03765 0.02953\n",
      " 0.03751 0.03579 0.02785 0.02889 0.02854 0.02843 0.03326 0.02854 0.0285\n",
      " 0.03292 0.03352 0.03346 0.03472 0.03244 0.03173 0.03262 0.03296 0.03679\n",
      " 0.0371  0.03723 0.03292 0.03264 0.02902 0.03362 0.03262 0.02936 0.03348\n",
      " 0.03313 0.03252 0.03306 0.0331  0.03271 0.03319 0.02797 0.03276 0.03203\n",
      " 0.03327 0.03424 0.03291 0.0331  0.03185 0.03443 0.03471 0.03387 0.02754\n",
      " 0.03301 0.01201 0.01235 0.012   0.01152 0.01183 0.01229 0.01211 0.0123\n",
      " 0.01254 0.01227 0.01166]\n"
     ]
    }
   ],
   "source": [
    "print('Clustered state standard errors: \\n', np.round(clustered_state_se_d, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above estimation results show that state-weighted and sample-weighted data produce estimates with higher magnitudes. I'm not sure why we are doing OLS regression on a binary dependent variable though. The estimates result in non-marginal shift effects for if the individual went to college (assuming that's what $coll = 1$ means). The standard errors for state-weighted and sample weighted data producer greater variability than standard errors from mean-weighted and non-weighted data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(e)** First, the merit states are found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merit states are: [34, 57, 58, 59, 61, 64, 71, 72, 85, 88]\n"
     ]
    }
   ],
   "source": [
    "merit_states = df[df['merit'] == 1]['state'].unique().tolist()\n",
    "print('Merit states are:', merit_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the corresponding states, the first year in which merit was received is found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "yr_implemented = []\n",
    "for i in merit_states:\n",
    "    yr_implemented.append(df[(df['merit'] == 1) & (df['state'] == i)]['year'].min())\n",
    "\n",
    "merit_states_beginning = pd.DataFrame({'year': yr_implemented}, index=merit_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding beginning merit years are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>1993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>1991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    year\n",
       "34  2000\n",
       "57  1998\n",
       "58  1993\n",
       "59  1997\n",
       "61  1999\n",
       "64  1996\n",
       "71  1991\n",
       "72  1998\n",
       "85  1997\n",
       "88  2000"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merit_states_beginning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Effects of merit are found for each state by differencing mean $coll$ for the year when merit was received with mean $coll$ from the year prior when merit had not yet been received. Aggregation of all merit-state differences will provide an asymptotically unbiased treatment effect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def effect(m):\n",
    "\n",
    "    merit_states = df[df['merit'] == 1]['state'].unique().tolist()\n",
    "    yr = []\n",
    "    for i in merit_states:\n",
    "        if m == 1:\n",
    "            yr.append(df[(df['merit'] == m) & (df['state'] == i)]['year'].min())\n",
    "        else:\n",
    "            yr.append(df[(df['merit'] == m) & (df['state'] == i)]['year'].max())\n",
    "    \n",
    "    merit_states_df = pd.DataFrame({'year': yr}, index=merit_states)\n",
    "\n",
    "    effects = []\n",
    "    for i in merit_states_df.index:\n",
    "        effects.append(df[(df['merit'] == m) &\n",
    "                          (df['state'] == i) &\n",
    "                          (df['year'] == merit_states_df.loc[i, 'year'])]['coll'].mean())\n",
    "\n",
    "    return effects\n",
    "\n",
    "effects_df = pd.DataFrame({'prior mean coll': np.round(effect(0), 4),\n",
    "                           'post mean coll': np.round(effect(1), 4)},\n",
    "                          index=merit_states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean effects for post and prior merit are presented below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior mean coll</th>\n",
       "      <th>post mean coll</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.4724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.5405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.3556</td>\n",
       "      <td>0.3793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.3361</td>\n",
       "      <td>0.4567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.4211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.4773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.4000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prior mean coll  post mean coll\n",
       "34           0.5154          0.4724\n",
       "57           0.4857          0.5405\n",
       "58           0.3556          0.3793\n",
       "59           0.3361          0.4567\n",
       "61           0.4390          0.4211\n",
       "64           0.3659          0.4773\n",
       "71           0.2708          0.4000\n",
       "72           0.3651          0.3889\n",
       "85           0.3333          0.3200\n",
       "88           0.3333          0.4074"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effects_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating state-level differences show some states experience negative effects on $coll$ after receiving the merit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prior mean coll</th>\n",
       "      <th>post mean coll</th>\n",
       "      <th>diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.5154</td>\n",
       "      <td>0.4724</td>\n",
       "      <td>-0.0430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.4857</td>\n",
       "      <td>0.5405</td>\n",
       "      <td>0.0548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.3556</td>\n",
       "      <td>0.3793</td>\n",
       "      <td>0.0237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.3361</td>\n",
       "      <td>0.4567</td>\n",
       "      <td>0.1206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.4211</td>\n",
       "      <td>-0.0179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.3659</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>0.1114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.2708</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.3651</td>\n",
       "      <td>0.3889</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>-0.0133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.4074</td>\n",
       "      <td>0.0741</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    prior mean coll  post mean coll    diff\n",
       "34           0.5154          0.4724 -0.0430\n",
       "57           0.4857          0.5405  0.0548\n",
       "58           0.3556          0.3793  0.0237\n",
       "59           0.3361          0.4567  0.1206\n",
       "61           0.4390          0.4211 -0.0179\n",
       "64           0.3659          0.4773  0.1114\n",
       "71           0.2708          0.4000  0.1292\n",
       "72           0.3651          0.3889  0.0238\n",
       "85           0.3333          0.3200 -0.0133\n",
       "88           0.3333          0.4074  0.0741"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "effects_df['diff'] = effects_df['post mean coll'] - effects_df['prior mean coll']\n",
    "effects_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The merit treatment effect is approximated as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.463"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "round(sum(effects_df['diff']), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X variables without including other predictors: \n",
      " ['ones', 'treatment'] \n",
      " \n",
      " X variables with other predictors: \n",
      " ['ones', 'treatment', 'lnincome', 'beer', 'age15to24', 'retprice'] \n",
      " \n",
      " State and year fixed effect variables: \n",
      " [29, 32, 10, 21, 14, 27, 22, 25, 2, 36, 9, 31, 34, 7, 17, 4, 16, 3, 33, 13, 15, 24, 19, 35, 11, 5, 12, 6, 38, 8, 23, 37, 28, 30, 26, 20, 18, 1, 1970, 1971, 1972, 1973, 1974, 1975, 1976, 1977, 1978, 1979, 1980, 1981, 1982, 1983, 1984, 1985, 1986, 1987, 1988, 1989, 1990, 1991, 1992, 1993, 1994, 1995, 1996, 1997, 1998, 1999]\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "def getFile(sub_dir):\n",
    "    return glob.glob('/home/akappes/WSU/' + sub_dir + '/*.csv')\n",
    "\n",
    "# i = 0\n",
    "# while i < len(getFile('512_MetricsII')):\n",
    "#     print(i, getFile('512_MetricsII')[i])\n",
    "#     i += 1\n",
    "#     if i > len(getFile('512_MetricsII')):\n",
    "#         break\n",
    "\n",
    "df = pd.read_csv(getFile('512_MetricsII')[3])\n",
    "df['treatment'] = 0\n",
    "df.loc[df[(df['state'] == 3) & (df['year'] >= 1989)].index.tolist(), 'treatment'] = 1\n",
    "\n",
    "bin_state = pd.DataFrame(0, columns=df['state'].unique().tolist()[:-1], index=df.index)\n",
    "bin_year = pd.DataFrame(0, columns=df['year'].unique().tolist()[:-1], index=df.index)\n",
    "\n",
    "for j in bin_state.columns:\n",
    "    bin_state.loc[df[df['state'] == j].index.tolist(), j] = 1\n",
    "\n",
    "for j in bin_year.columns:\n",
    "    bin_year.loc[df[df['year'] == j].index.tolist(), j] = 1\n",
    "\n",
    "ones = pd.DataFrame({'ones': 1}, index=df.index)\n",
    "df = pd.concat([ones, df, bin_state, bin_year], axis=1)\n",
    "df[np.isnan(df)] = 0\n",
    "\n",
    "cols = df.columns.tolist()\n",
    "n = int(cols.index('treatment'))\n",
    "cols = [cols[0]] + [cols[n]] + cols[1:n] + cols[n + 1:]\n",
    "df = df[cols]\n",
    "\n",
    "# (a) #\n",
    "y = df['cigsale']\n",
    "\n",
    "X_without = df.drop(['state', 'year', 'cigsale', 'lnincome', 'beer',\n",
    "                             'age15to24', 'retprice'], axis=1)\n",
    "\n",
    "X_with = df.drop(['state', 'year', 'cigsale'], axis=1)\n",
    "\n",
    "print('X variables without including other predictors: \\n', X_without.columns[0:2].tolist(),\n",
    "     '\\n \\n X variables with other predictors: \\n', X_with.columns[0:6].tolist(),\n",
    "     '\\n \\n State and year fixed effect variables: \\n', X_without.columns[2:].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(a)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated parameters without other predictors: \n",
      " [[101.623 -27.349]] \n",
      " \n",
      " Estimated paramters with other predictors: \n",
      " [[234.793 -17.649  -3.067  -1.185  52.477  -0.483]] \n",
      " \n",
      " State clustered standard errors without other predictors: \n",
      " [1.913 2.721 2.453 3.242 2.22  4.753 1.819 2.394 7.042 1.862 2.94  1.854\n",
      " 2.115 2.008 1.914 2.17  2.377 2.149 1.863 2.348 2.122 2.824 1.951 4.72\n",
      " 1.838 2.43  1.842 2.041 1.784 2.286 1.93  1.979 1.695 2.53  1.987 2.39\n",
      " 2.196 1.799 2.204 2.79  1.422 1.422 1.422 1.422 1.422 1.422 1.422 1.422\n",
      " 1.422 1.422 1.422 1.422 1.422 1.422 1.422 1.422 1.422 1.422 1.422 1.421\n",
      " 1.421 1.421 1.421 1.421 1.421 1.421 1.421 1.421 1.421 1.421] \n",
      " \n",
      " State clustered standard errors with other predictors: \n",
      " [7.5020e+00 2.9490e+00 3.2190e+00 1.1900e-01 4.4846e+01 2.6000e-02\n",
      " 2.2360e+00 2.8280e+00 2.1480e+00 4.0320e+00 2.1210e+00 2.6260e+00\n",
      " 6.2630e+00 2.1430e+00 2.8700e+00 2.1620e+00 2.0770e+00 2.2360e+00\n",
      " 2.5610e+00 2.1600e+00 2.5700e+00 2.2020e+00 2.3790e+00 2.6080e+00\n",
      " 2.2540e+00 3.2720e+00 2.1670e+00 5.3820e+00 2.0440e+00 2.4870e+00\n",
      " 2.1230e+00 2.4050e+00 2.0090e+00 2.3440e+00 2.8150e+00 2.2330e+00\n",
      " 2.0290e+00 2.3160e+00 2.1020e+00 2.4100e+00 2.1230e+00 2.0700e+00\n",
      " 2.1100e+00 2.5970e+00 1.0537e+01 1.0547e+01 3.2012e+01 3.2222e+01\n",
      " 3.2152e+01 3.2117e+01 3.2205e+01 3.2287e+01 3.2425e+01 3.2403e+01\n",
      " 3.2289e+01 3.2272e+01 3.2181e+01 3.2155e+01 3.2766e+01 3.2761e+01\n",
      " 3.2798e+01 3.2771e+01 3.2759e+01 3.2781e+01 3.2775e+01 3.2420e+01\n",
      " 3.2467e+01 3.2484e+01 3.2583e+01 3.2682e+01 3.2761e+01 3.2742e+01\n",
      " 2.8600e+00 2.3840e+00]\n"
     ]
    }
   ],
   "source": [
    "est_without = estimate(y, X_without, df)\n",
    "est_with = estimate(y, X_with, df)\n",
    "params_without = est_without.beta()\n",
    "params_with = est_with.beta()\n",
    "resids_without = est_without.error(params_without)\n",
    "resids_with = est_with.error(params_with)\n",
    "clustered_s_without = est_without.se_cluster_s('state', resids_without)\n",
    "clustered_s_with = est_with.se_cluster_s('state', resids_with)\n",
    "\n",
    "print('Estimated parameters without other predictors: \\n', np.round(params_without[0:2].T, 3),\n",
    "     '\\n \\n Estimated paramters with other predictors: \\n', np.round(params_with[0:6].T, 3),\n",
    "     '\\n \\n State clustered standard errors without other predictors: \\n', np.round(clustered_s_without, 3),\n",
    "     '\\n \\n State clustered standard errors with other predictors: \\n', np.round(clustered_s_with, 3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
